{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XP3YOprVwyX"
   },
   "source": [
    "# Exploring Gender Biases in Word2vec \n",
    "\n",
    "This notebook defines genism's model and trains it with the Gutenburg and Wikipedia datasets. We also explore different embedding metrics to define a base comparision before we implement debiasing techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4LSSjBdfJhI",
    "outputId": "dfd47a58-6b57-4110-9160-f206ad21f54a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/user/opt/anaconda3/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: torchtext in /Users/user/opt/anaconda3/lib/python3.8/site-packages (0.12.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torchtext) (1.11.0)\n",
      "Requirement already satisfied: numpy in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torchtext) (1.20.3)\n",
      "Requirement already satisfied: tqdm in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torchtext) (4.62.3)\n",
      "Requirement already satisfied: requests in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torchtext) (2.26.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from torch==1.11.0->torchtext) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from requests->torchtext) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from requests->torchtext) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from requests->torchtext) (3.2)\n",
      "Requirement already satisfied: gensim in /Users/user/opt/anaconda3/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/user/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.7.1)\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#library imports\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "import tempfile\n",
    "from sklearn.decomposition import PCA\n",
    "!pip install torch\n",
    "import torch\n",
    "!pip install torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "#gutenberg data import\n",
    "# from gutenberg_data import get_urls, read_data_from_urls\n",
    "!pip install gensim\n",
    "#models import\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# import custom_word2vec\n",
    "\n",
    "#plots\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#had trouble importing file so copy pasted custom word2vec here\n",
    "#imports\n",
    "import torch\n",
    "from torch import nn, optim, sigmoid\n",
    "# import tensorflow\n",
    "# from keras.preprocessing.sequence import skipgrams \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#check which device pytorch will use, set default tensor type to cuda\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "print(f'Using {device} device')\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor') #run on google colab\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHow to Use:\\n- define a Custom_Word2Vec instance with the hyperparamters\\n- call the .train() function\\n- acess trained embeddings via .embedding()\\n\\n\\nExample:\\nword_2_vec = Custom_Word2Vec([[\\'he\\', \\'was\\', \\'cool\\'], [\\'she\\', \\'loved\\', \\'meat\\'], [\\'you\\', \\'do\\', \\'nothing\\']])\\nword_2_vec.train()\\nprint (\"embedding: \", word_2_vec.embedding(\\'he\\'))\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Custum Word2Vec\n",
    "\n",
    "For Zhao et al.'s and Savani et al.'s debiasing methods, we created our own model and skip-gram traning loops below.\n",
    "\"\"\"\n",
    "\n",
    "class skipgram(nn.Module):\n",
    "    \"\"\"\n",
    "    defines the layers of the word2vec model\n",
    "    \n",
    "    Embedding Layer Target - target words to compare the context words (output embeddings)\n",
    "    Embedding Layer Context - context words to compare to target words\n",
    "    Linear - after the dot product of target and context layers, this linear layer transforms the output to 1 dim to compare with 1 = relevant pair, 0 - irrelevant pair labels \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size_vocab, embedding_dim):\n",
    "        super(skipgram, self).__init__()\n",
    "        self.embeddings_target =  nn.Embedding(size_vocab+1, embedding_dim, max_norm=1).to(device) #what we care about\n",
    "        self.embeddings_context = nn.Embedding(size_vocab+1, embedding_dim, max_norm=1).to(device) #used in loss calculation\n",
    "        self.linear = nn.Linear(embedding_dim,1)\n",
    "        \n",
    "\n",
    "    def forward(self, target_tensor, context_tensor): #loss\n",
    "        embedding_t = self.embeddings_target(target_tensor)\n",
    "        embedding_c = self.embeddings_context(context_tensor)\n",
    "        \n",
    "        return torch.sigmoid(self.linear(torch.mul(embedding_t, embedding_c))).squeeze(1)\n",
    "\n",
    "class Custom_Word2Vec:\n",
    "    \"\"\"\n",
    "    defines the word2vec model\n",
    "    \n",
    "    hyperparameters: \n",
    "    - embedding_dim: embedding dimension (default 10)\n",
    "    - LR: learning rate for optimizer (default 0.01)\n",
    "    - window_size: window of context words to generate skip-gram pairs (default 10)\n",
    "    - EPOCHS: number of iterations to run training (default 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sentance_tokens, embedding_dim=10, LR=0.01, window_size=10, EPOCHS=10):\n",
    "        #hyperparamters\n",
    "        self.window_size = window_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lr = LR\n",
    "        self.epochs = EPOCHS\n",
    "        \n",
    "        #data, corpus\n",
    "        self.sentance_tokens = sentance_tokens\n",
    "        self.corpus_vocab = self.corpus_vocab()\n",
    "        self.size_vocab = len(self.corpus_vocab)\n",
    "        \n",
    "        #model, loss, optimizer\n",
    "        self.model = skipgram(self.size_vocab, self.embedding_dim)\n",
    "        self.loss_fcn = nn.BCELoss() # use binary cross entropy as the loss function\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr) #use stochiastic gradient descent\n",
    "\n",
    "    \n",
    "    def corpus_vocab(self):\n",
    "        \"\"\"\n",
    "        define a dictionary where keys are words, and the values are the unique ids of the words\n",
    "        \"\"\"\n",
    "\n",
    "        #count frequency of each word\n",
    "        vocab_counts = {}\n",
    "        for sentance in self.sentance_tokens:\n",
    "            for word in sentance:\n",
    "                vocab_counts[word] = vocab_counts.get(word, 0) + 1\n",
    "\n",
    "\n",
    "        #create corpus by assigning unique ids\n",
    "        i = 1\n",
    "        corpus_vocab = {}\n",
    "        for k, v in sorted(vocab_counts.items(), key=lambda item: item[1]):\n",
    "            corpus_vocab[k] = i\n",
    "            i+=1\n",
    "\n",
    "        return corpus_vocab\n",
    "\n",
    "    def create_target_context_pairs(self):\n",
    "        \"\"\"\n",
    "        generate [(target, context), 1] pairs as positive samples - contextually relevant pair\n",
    "        and [(target, random), 0] pairs as negative samples - contextually irrelevant pair\n",
    "        \"\"\"\n",
    "        \n",
    "        #get the word ids from the corpus for all the sentances\n",
    "        word_ids_datatset = [[self.corpus_vocab[word] for word in sentance] for sentance in self.sentance_tokens]\n",
    "        \n",
    "        #generate skipgrams (pairs) for all sentances\n",
    "        skip_grams = [skipgrams(word_ids, vocabulary_size=self.size_vocab, window_size=self.window_size) for word_ids in word_ids_datatset]\n",
    "        \n",
    "        return skip_grams\n",
    "    \n",
    "    def embedding(self, word):\n",
    "        idx = self.corpus_vocab[word]\n",
    "        embedding = self.model.embeddings_target(torch.Tensor([idx]).long())\n",
    "        return embedding.detach().cpu().numpy()[0]\n",
    "    \n",
    "    def train(self, plot=True):\n",
    "        \n",
    "        skip_grams = self.create_target_context_pairs() #get pairs\n",
    "\n",
    "        losses_epochs = []\n",
    "\n",
    "        #loop over epochs\n",
    "        for epoch in range(self.epochs):\n",
    "            total_loss = 0\n",
    "            \n",
    "            #iterate through all target, context pairs\n",
    "            for pairs, labels in skip_grams:\n",
    "                # zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # calculate loss \n",
    "                sentance_losses = []\n",
    "                for i in range (len(pairs)): #pairs in a sentance\n",
    "                    target_tensor = torch.Tensor([pairs[i][0]]).long() #target word\n",
    "                    context_tensor =  torch.Tensor([pairs[i][1]]).long() #context word (true or random)\n",
    "                    label = torch.Tensor([labels[i]]).float() # 1- relevant, 0 - irrelevent\n",
    "\n",
    "                    output = self.model(target_tensor, context_tensor)\n",
    "                    loss_pair = self.loss_fcn(output,label)\n",
    "                    sentance_losses.append(loss_pair)\n",
    "\n",
    "\n",
    "                #loss backward, optimizer step\n",
    "                if sentance_losses:\n",
    "                    loss = torch.sum(torch.stack(sentance_losses))\n",
    "                    loss.backward()\n",
    "                    total_loss+= loss.item()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "            print('Epoch:', epoch+1, ' Training Loss:', total_loss)\n",
    "            losses_epochs.append(total_loss)\n",
    "        \n",
    "        # plot loss over epochs\n",
    "        if plot:\n",
    "            epochs = [i+1 for i in range(self.epochs)]\n",
    "            plt.plot(epochs,losses_epochs)\n",
    "            plt.title('Loss vs Epochs for Word2Vec Skip-Gram Model')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Cost')\n",
    "            plt.show()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "How to Use:\n",
    "- define a Custom_Word2Vec instance with the hyperparamters\n",
    "- call the .train() function\n",
    "- acess trained embeddings via .embedding()\n",
    "\n",
    "\n",
    "Example:\n",
    "word_2_vec = Custom_Word2Vec([['he', 'was', 'cool'], ['she', 'loved', 'meat'], ['you', 'do', 'nothing']])\n",
    "word_2_vec.train()\n",
    "print (\"embedding: \", word_2_vec.embedding('he'))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhIMaI4vV8VI"
   },
   "source": [
    "## 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RzDntNYcmVec"
   },
   "outputs": [],
   "source": [
    "def create_tokens(data):\n",
    "    \"\"\"\n",
    "    creates tokenized list with puncuation and digits removed and lowercase words \n",
    "\n",
    "    :param data: list of strings\n",
    "    :return: a list of tokens \n",
    "    \"\"\" \n",
    "    tokens = []\n",
    "    for sentance in data:\n",
    "        sentance = sentance.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "        sentance = sentance.translate(str.maketrans('', '', string.digits)) #remove digits\n",
    "        tokenizer = get_tokenizer(\"basic_english\", language=\"en\") #remove unessasary characters, splits into spaces\n",
    "        tokens.append(tokenizer(sentance))\n",
    "  \n",
    "    return tokens\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tTskJcpBpDEt"
   },
   "source": [
    "**Gutenburg Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zsTQM81GpDEu",
    "outputId": "12fedd03-76dd-4c73-f874-c921b02c98fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PcqA9wapDEv"
   },
   "source": [
    "**Wikipedia Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdY5fDuEpDEw",
    "outputId": "5c3c79b9-63a1-4f27-a540-fa70fc990d8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGQ-ic0KpDEw"
   },
   "source": [
    "## 2 - Define Word2Vec - Genism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vADvrY8rDeuq"
   },
   "source": [
    "**Define word 2 vec model** <br>\n",
    "\n",
    "Using: Skip-gram training algorithm. \n",
    "\n",
    "Hyperparameters:\n",
    "- min_freq: choosing the top N most frequent words - for easier training \n",
    "- size: embedding size. We use 300 as per Bolukbasi et al.\n",
    "- window: the window used for looking at context and center words when traing the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "cHtqmychpDEx",
    "outputId": "866140be-8705-4864-b7a7-7598b1f38101"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oi3IPi53pDEx"
   },
   "outputs": [],
   "source": [
    "#Useful helper functions for model\n",
    "\n",
    "def check_w_embedding(word_lists, model, printRemoved):\n",
    "    '''\n",
    "    checks if the embedding exists for the given word, and if not deletes it from the lists. \n",
    "    if printRemoved = true, it also declares the words that were not in the model embeddings. \n",
    "    '''\n",
    "    new_w_lists = []\n",
    "    \n",
    "    for word_list in word_lists:\n",
    "        new_w_l = []\n",
    "        for w in word_list: \n",
    "            if w in model.wv.key_to_index:\n",
    "                new_w_l.append(w)\n",
    "            else:\n",
    "                if printRemoved:\n",
    "                    print (\"Word\", w, \" is not in the model\")\n",
    "                    \n",
    "        new_w_lists.append(new_w_l)\n",
    "    \n",
    "    return new_w_lists\n",
    "    \n",
    "\n",
    "def w_vec(word, model):\n",
    "    '''\n",
    "    returns the word embedding of the input word\n",
    "    '''\n",
    "    return model.wv[word]\n",
    "   \n",
    "\n",
    "def cos_sim(a,b):\n",
    "    '''\n",
    "    returns the cosine similarity between 2 word embeddings \n",
    "    '''\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYDVA5_wpDEy"
   },
   "source": [
    "Now, save the embeddings to use in debiasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e_XcKc4SpDEy"
   },
   "outputs": [],
   "source": [
    "# with open('gutenburg_embeddings.txt', 'w') as f:\n",
    "#     for idx, key in enumerate(list(model_g.wv.index_to_key)):\n",
    "#         embedding = ' '.join(str(v) for v in model_g.wv.get_vector(key))\n",
    "#         f.write(key + \" \" + embedding+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "J9hErZ1ApDEz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiki_files/wikipedia-en-0.json\n",
      "Wiki_files/wikipedia-en-1.json\n",
      "Wiki_files/wikipedia-en-2.json\n",
      "Wiki_files/wikipedia-en-3.json\n",
      "Wiki_files/wikipedia-en-4.json\n",
      "Wiki_files/wikipedia-en-5.json\n",
      "Wiki_files/wikipedia-en-6.json\n",
      "Wiki_files/wikipedia-en-7.json\n",
      "Wiki_files/wikipedia-en-8.json\n",
      "Wiki_files/wikipedia-en-9.json\n",
      "Wiki_files/wikipedia-en-10.json\n",
      "Wiki_files/wikipedia-en-11.json\n",
      "Wiki_files/wikipedia-en-12.json\n",
      "Wiki_files/wikipedia-en-13.json\n",
      "Wiki_files/wikipedia-en-14.json\n",
      "Wiki_files/wikipedia-en-15.json\n",
      "Wiki_files/wikipedia-en-16.json\n",
      "Wiki_files/wikipedia-en-17.json\n",
      "Wiki_files/wikipedia-en-18.json\n",
      "Wiki_files/wikipedia-en-19.json\n"
     ]
    }
   ],
   "source": [
    "min_freq = 1\n",
    "size = 300\n",
    "window = 10\n",
    "\n",
    "\n",
    "#wikipedia model\n",
    "model_w = Word2Vec(min_count=min_freq, vector_size=size, window=window, sg=1) #sg=1 is the skip-gram training algorithm\n",
    "model_w.init_weights()\n",
    "\n",
    "#Wikipedia\n",
    "for file in range(20):\n",
    "    f_name = 'Wiki_files/wikipedia-en-' + str(file) + '.json'\n",
    "    print(f_name)\n",
    "    f = open(f_name)\n",
    "    sentences_wikipedia = []\n",
    "    train_data = json.load(f)\n",
    "    for article in train_data:        \n",
    "        train_data_w = str(article).split('.')\n",
    "        sentences_wikipedia += create_tokens(train_data_w)\n",
    "    if file == 0:\n",
    "        model_w.build_vocab(sentences_wikipedia)\n",
    "    else:\n",
    "        model_w.build_vocab(sentences_wikipedia,update=True)\n",
    "#         model_w.train(sentences_wikipedia)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "with open('wikipedia_embeddings.txt', 'w') as f:\n",
    "    for idx, key in enumerate(list(model_w.wv.index_to_key)):\n",
    "        embedding = ' '.join(str(v) for v in model_w.wv.get_vector(key))\n",
    "        f.write(key + \" \" + embedding+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VzYjT6CqAJv"
   },
   "source": [
    "## 3 - Define/Train Word2Vec - Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "wNHWm-S7qSiD",
    "outputId": "765dcb4b-60da-479a-db8a-b72f7493fff0"
   },
   "outputs": [],
   "source": [
    "# gutenburg\n",
    "embedding_dim=10\n",
    "LR=0.01\n",
    "window_size=2\n",
    "EPOCHS=2\n",
    "\n",
    "# word_2_vec_gutenburg = Custom_Word2Vec(sentences_gutenburg, embedding_dim, LR, window_size, EPOCHS)\n",
    "# word_2_vec_gutenburg.train()\n",
    "\n",
    "# check first embedding\n",
    "# embedding_1 = word_2_vec_gutenburg.model.embeddings_target(torch.Tensor([1]).long())\n",
    "# print (\"embedding tensor: \", embedding_1.detach().cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9jws4VUXiuh"
   },
   "source": [
    "## 4 - Measuring Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXVe1S3hpDEz"
   },
   "source": [
    "### 4.1 - Construct the g subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yLxbqwVpDEz"
   },
   "source": [
    "First, define gendered words and pairs ground truth (taken from Bolukbasi et al.) Using PCA, define the gendered subspace g, by taking the most prominent dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WGwiksMipDE0",
    "outputId": "ed4a1e49-169d-4e8a-d123-17f2774b239d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA variance ratio: [3.7052581e-01 2.3016405e-01 2.0911980e-01 1.9019029e-01 7.7268632e-15\n",
      " 5.3134297e-16]\n",
      "PCA singular values: [6.2878147e-02 4.9557485e-02 4.7237627e-02 4.5048948e-02 9.0801313e-09\n",
      " 2.3811018e-09]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gender_subspace_matrix(model, gender_pairs):\n",
    "    '''\n",
    "    create matrix of the gender space using gender pairs\n",
    "        \n",
    "    '''\n",
    "    word_directions = []\n",
    "    for word_pair in gender_pairs:\n",
    "        f_word = w_vec(word_pair[0],model)\n",
    "        m_word = w_vec(word_pair[1],model)\n",
    "        dif = f_word-m_word\n",
    "        word_directions.append(dif)\n",
    "\n",
    "    return np.array(word_directions)\n",
    "\n",
    "\n",
    "def define_vector_g(model, gender_pairs):\n",
    "    word_directions = gender_subspace_matrix(model, gender_pairs) \n",
    "\n",
    "    #PCA of word direction\n",
    "    pca = PCA(n_components=len(gender_pairs))\n",
    "    pca.fit(word_directions)\n",
    "\n",
    "    #print graph of PCA dimensions to determine how many dimensions should be kept\n",
    "    print(\"PCA variance ratio:\", pca.explained_variance_ratio_)\n",
    "    print(\"PCA singular values:\", pca.singular_values_)\n",
    "\n",
    "    #plot graph of eigenvalue variance (basically how relevant each dimension was)\n",
    "    len_var = len(pca.explained_variance_ratio_)\n",
    "    plt.bar(range(1,len_var+1),pca.explained_variance_ratio_)\n",
    "    plt.xlabel(\"Matrix Variance Column\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.title(\"Significance of each eigenvector\")\n",
    "\n",
    "    #use the 1 most prominent dimension\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(word_directions)\n",
    "    g = pca.components_\n",
    "    \n",
    "    return g\n",
    "\n",
    "#gender pairs\n",
    "#gender_pairs = [['she','he'],['her','his'],['woman','man'],['Mary','John'],['herself','himself'],['daughter','son'],['mother','father'],['gal','guy'],['girl','boy'],['female','male']]\n",
    "gender_pairs = [['she','he'],['her','his'],['mother','father'],['daughter','son'], ['mother','father'],['female','male']]\n",
    "# gender_pairs = check_w_embedding(gender_pairs, model_g, True)\n",
    "gender_pairs = check_w_embedding(gender_pairs, model_w, True)\n",
    "\n",
    "\n",
    "#define g subspace for each dataset\n",
    "# g_gutenburg = define_vector_g(model_g, gender_pairs)\n",
    "g_wikipedia = define_vector_g(model_w,gender_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ylrwq0MXxYN"
   },
   "source": [
    "### 4.2 - Direct Bias\n",
    "\n",
    "To measure direct bias, we will be using the equation from Bolukbasi et al. shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI6_1ww2pDE1"
   },
   "source": [
    "<img src=\"img/Direct_Bias.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBrC38VkpDE1"
   },
   "source": [
    "We will use the same gender neutral words that have been collected from the paper which is \n",
    "denoted by N. As well, we will utilize the paper’s gender directions (vector from one word to another) \n",
    "which were verified by crowdsourcing. The gender subspace g will be the unit vector g that captures the\n",
    "gender directions, computed by principal components in the paper. Finally, we will consider c, which is the \n",
    "strictness of bias, as a hyperparameter in our experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qc-4WChgpDE1",
    "outputId": "cced117f-befb-4e48-d27c-542cd3e53a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gendered word set after filtering:  ['he', 'his', 'her', 'she', 'him', 'man', 'women', 'men', 'woman', 'spokesman', 'wife', 'himself', 'son', 'mother', 'father', 'chairman', 'daughter', 'husband', 'guy', 'girls', 'girl', 'boy', 'boys', 'brother', 'spokeswoman', 'female', 'sister', 'male', 'herself', 'brothers', 'dad', 'actress', 'mom', 'sons', 'girlfriend', 'daughters', 'lady', 'boyfriend', 'sisters', 'mothers', 'king', 'businessman', 'grandmother', 'grandfather', 'deer', 'ladies', 'uncle', 'males', 'congressman', 'grandson', 'bull', 'queen', 'businessmen', 'wives', 'widow', 'nephew', 'bride', 'females', 'aunt', 'lesbian', 'chairwoman', 'fathers', 'moms', 'maiden', 'granddaughter', 'lads', 'lion', 'gentleman', 'fraternity', 'bachelor', 'niece', 'bulls', 'husbands', 'prince', 'colt', 'salesman', 'hers', 'dude', 'beard', 'filly', 'princess', 'lesbians', 'councilman', 'actresses', 'gentlemen', 'stepfather', 'monks', 'lad', 'sperm', 'testosterone', 'nephews', 'maid', 'daddy', 'mare', 'fiance', 'fiancee', 'kings', 'dads', 'waitress', 'maternal', 'heroine', 'nieces', 'girlfriends', 'sir', 'stud', 'mistress', 'lions', 'womb', 'grandma', 'maternity', 'estrogen', 'widows', 'gelding', 'diva', 'nuns', 'czar', 'countrymen', 'penis', 'bloke', 'nun', 'brides', 'housewife', 'spokesmen', 'suitors', 'menopause', 'monastery', 'motherhood', 'brethren', 'stepmother', 'prostate', 'hostess', 'schoolboy', 'brotherhood', 'fillies', 'stepson', 'congresswoman', 'uncles', 'witch', 'monk', 'viagra', 'paternity', 'suitor', 'sorority', 'macho', 'businesswoman', 'gal', 'statesman', 'schoolgirl', 'fathered', 'goddess', 'hubby', 'stepdaughter', 'blokes', 'dudes', 'strongman', 'uterus', 'grandsons', 'studs', 'mama', 'godfather', 'hens', 'hen', 'mommy', 'boyhood', 'baritone', 'grandmothers', 'grandpa', 'boyfriends', 'feminism', 'countryman', 'stallion', 'heiress', 'queens', 'witches', 'aunts', 'semen', 'fella', 'granddaughters', 'chap', 'widower', 'salesmen', 'convent', 'vagina', 'beau', 'beards', 'handyman', 'maids', 'gals', 'housewives', 'horsemen', 'obstetrics', 'fatherhood', 'councilwoman', 'princes', 'matriarch', 'colts', 'ma', 'fraternities', 'pa', 'fellas', 'councilmen', 'dowry', 'barbershop', 'fraternal', 'ballerina']\n",
      "Direct metric wiki: 0.05577021304769271\n"
     ]
    }
   ],
   "source": [
    "def calculate_direct_metric(gendered_word_set, model, c, g):\n",
    "    '''\n",
    "    calculate the direct bias using Bolukbasi et al.'s equation\n",
    "    '''\n",
    "    cosine_add = 0\n",
    "    for word in gendered_word_set:\n",
    "        cosine_add += np.abs(cos_sim(w_vec(word,model),g[0]))**c\n",
    "    \n",
    "    return cosine_add/len(gendered_word_set)\n",
    "    \n",
    "\n",
    "c = 1 #hyperparameter\n",
    "#gendered_words = 'he, his, her, she, him, man, women, men, woman, spokesman, wife, himself, son'\n",
    "gendered_words = 'he, his, her, she, him, man, women, men, woman, spokesman, wife, himself, son, mother, father, chairman, daughter, husband, guy, girls, girl, boy, boys, brother, spokeswoman, female, sister, male, herself, brothers, dad, actress, mom, sons, girlfriend, daughters, lady, boyfriend, sisters, mothers, king, businessman, grandmother, grandfather, deer, ladies, uncle, males, congressman, grandson, bull, queen, businessmen, wives, widow, nephew, bride, females, aunt, prostate cancer, lesbian, chairwoman, fathers, moms, maiden, granddaughter, younger brother, lads, lion, gentleman, fraternity, bachelor, niece, bulls, husbands, prince, colt, salesman, hers, dude, beard, filly, princess, lesbians, councilman, actresses, gentlemen, stepfather, monks, ex girlfriend, lad, sperm, testosterone, nephews, maid, daddy, mare, fiance, fiancee, kings, dads, waitress, maternal, heroine, nieces, girlfriends, sir, stud, mistress, lions, estranged wife, womb, grandma, maternity, estrogen, ex boyfriend, widows, gelding, diva, teenage girls, nuns, czar, ovarian cancer, countrymen, teenage girl, penis, bloke, nun, brides, housewife, spokesmen, suitors, menopause, monastery, motherhood, brethren, stepmother, prostate, hostess, twin brother, schoolboy, brotherhood, fillies, stepson, congresswoman, uncles, witch, monk, viagra, paternity, suitor, sorority, macho, businesswoman, eldest son, gal, statesman, schoolgirl, fathered, goddess, hubby, stepdaughter, blokes, dudes, strongman, uterus, grandsons, studs, mama, godfather, hens, hen, mommy, estranged husband, elder brother, boyhood, baritone, grandmothers, grandpa, boyfriends, feminism, countryman, stallion, heiress, queens, witches, aunts, semen, fella, granddaughters, chap, widower, salesmen, convent, vagina, beau, beards, handyman, twin sister, maids, gals, housewives, horsemen, obstetrics, fatherhood, councilwoman, princes, matriarch, colts, ma, fraternities, pa, fellas, councilmen, dowry, barbershop, fraternal, ballerina'\n",
    "gendered_words = gendered_words.split(\", \")\n",
    "\n",
    "#gendered_word_set_w = set(check_w_embedding([gendered_words],model_w,False)[0])\n",
    "#gendered_word_set_g = set(check_w_embedding([gendered_words],model_g,False)[0])\n",
    "#gendered_word_set = list(gendered_word_set_w.intersection(gendered_word_set_g))\n",
    "\n",
    "# gendered_word_set = check_w_embedding([gendered_words],model_g,False)[0]\n",
    "# print(\"gendered word set after filtering: \", gendered_word_set)\n",
    "\n",
    "gendered_word_set = check_w_embedding([gendered_words],model_w,False)[0]\n",
    "print(\"gendered word set after filtering: \", gendered_word_set)\n",
    "\n",
    "# direct_gutenburg = calculate_direct_metric(gendered_word_set, model_g, c, g_gutenburg)\n",
    "direct_wikipedia = calculate_direct_metric(gendered_word_set, model_w, c, g_wikipedia)\n",
    "\n",
    "# print(\"Direct metric gutenburg:\", direct_gutenburg)\n",
    "print(\"Direct metric wiki:\", direct_wikipedia)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMIUMyqsX57J"
   },
   "source": [
    "### 4.3 - Indirect Bias\n",
    "\n",
    "To measure indirect bias, we will be using the equation from Bolukbasi et al. shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrOSjUQspDE2"
   },
   "source": [
    "<img src=\"img/Indirect_Bias.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6krHTKxepDE2"
   },
   "source": [
    "$w_{\\perp}$ is defined as $w_{\\perp} = w - w_{g}$ where $w_{g}=(w*g)*g$ as mentioned in the paper. We will be using the g subspace calculated above. As for the word pairs, we will run a few experiments. The first will be the most extreme words in the softball-football direction as mentioned in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kGyyr-NqpDE2",
    "outputId": "48e36e83-23b3-492e-9a74-eeac5e2bbe8c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_w_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f2/_jt1y5ms3kgg3tr8n5ccy95h0000gn/T/ipykernel_66697/1136593402.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mextreme_words_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompare_word_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_w_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mextreme_words_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompare_word_w\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mmetrics_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_indirect_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextreme_words_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_word_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_wikipedia\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indirect β values for word 'clean':\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_w_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "def calculate_indirect_metric(g, w, v):\n",
    "    wg = np.dot(np.dot(w,g[0]),g[0])\n",
    "    vg = np.dot(np.dot(v,g[0]),g[0])\n",
    "    w_norm_vec = w-wg\n",
    "    v_norm_vec = v-vg\n",
    "    w_norm = norm(w_norm_vec)\n",
    "    v_norm = norm(v_norm_vec)\n",
    "    \n",
    "    return (np.dot(w,v) - np.dot(w_norm_vec,v_norm_vec)/(w_norm*v_norm))/np.dot(w,v)\n",
    "\n",
    "def compare_indirect_metrics(words, c_word, model,g):\n",
    "    metrics=\"\"\n",
    "    for w in words:\n",
    "        metrics+=str(calculate_indirect_metric(g, w_vec(c_word,model), w_vec(w,model)))+\", \"\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "#Future Experiment - Bolukbasi et al. \n",
    "#extreme_words_w = ['pitcher','bookkeeper', 'receptionist', 'nurse', 'waitress']\n",
    "#compare_word_w = 'softball'\n",
    "#extreme_words_m = ['footballer','businessman', 'pundit', 'maestro', 'cleric']\n",
    "#compare_word_m = 'football'\n",
    "\n",
    "#Experiment 1\n",
    "extreme_words_w = ['family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "compare_word_w = 'clean'\n",
    "extreme_words_m = ['paper', 'money', 'office', 'business', 'meeting']\n",
    "compare_word_m = 'manager'\n",
    "\n",
    "\n",
    "extreme_words_w,[compare_word_w] = check_w_embedding([extreme_words_w,[compare_word_w]], model_w, True)\n",
    "metrics_w = compare_indirect_metrics(extreme_words_w, compare_word_w, model_w,g_wikipedia)\n",
    "print(\"indirect β values for word 'clean':\", metrics_w)\n",
    "\n",
    "extreme_words_m,[compare_word_w] = check_w_embedding([extreme_words_m,[compare_word_m]], model_w, True)\n",
    "metrics_m = compare_indirect_metrics(extreme_words_m, compare_word_m, model_w,g_wikipedia)\n",
    "print(\"indirect β values for word 'manager':\", metrics_m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOv0RFFOX9NP"
   },
   "source": [
    "### 4.4 - WEAT Metric\n",
    "\n",
    "To measure WEAT, we used the formula defined in Caliskan et al., which is an additional direct bias measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OfIcsZSepDE3"
   },
   "source": [
    "<img src=\"img/WEAT.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QNYpB3AopDE3"
   },
   "outputs": [],
   "source": [
    "def s_word_A_B(w,A,B,model):\n",
    "    mean_A_sum = 0\n",
    "    mean_B_sum = 0\n",
    "    w_v = w_vec(w,model)\n",
    "    \n",
    "    for a in A:\n",
    "        a_vec = w_vec(a,model)\n",
    "        mean_A_sum +=cos_sim(w_v,a_vec)\n",
    "    \n",
    "    for b in B:\n",
    "        b_vec = w_vec(b,model)\n",
    "        mean_B_sum +=cos_sim(w_v,b_vec)\n",
    "        \n",
    "    return mean_A_sum/len(A) - mean_B_sum/len(B)\n",
    "\n",
    "def s_X_Y_A_B(X,Y,A,B,model):\n",
    "    sum_X = 0\n",
    "    sum_Y = 0\n",
    "    \n",
    "    for x in X:\n",
    "        sum_X += s_word_A_B(x,A,B,model)\n",
    "        \n",
    "    for y in Y:\n",
    "        sum_Y += s_word_A_B(y,A,B,model)\n",
    "    \n",
    "    return sum_X - sum_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e16kg8Z6pDE3"
   },
   "source": [
    "Now, lets run experiments on the models <br>\n",
    "A and B are the attribute word groups (8 words each), and X,Y are the target words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "z3OwU4I6pDE3",
    "outputId": "a7c7a064-6be0-4af6-ef77-d450677946e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT Exp 1: 0.0066366950632072985\n",
      "WEAT Exp 2: -0.045715197964455\n"
     ]
    }
   ],
   "source": [
    "#Experiment 1 - work/family\n",
    "A = ['tie', 'manager', 'work', 'paper', 'money', 'office', 'business', 'meeting']\n",
    "B = ['home', 'parents', 'children', 'family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "X = ['he', 'him']\n",
    "Y = ['she', 'her'] \n",
    "\n",
    "A,B,X,Y = check_w_embedding([A,B,X,Y], model_w, True)\n",
    "metric_exp_1_w = s_X_Y_A_B(X,Y,A,B,model_w)\n",
    "\n",
    "print (\"WEAT Exp 1:\", metric_exp_1_w)\n",
    "\n",
    "#Experiment 2 - professions\n",
    "A_2 = ['police', 'manager', 'business', 'lawyers', 'engineer', 'program', 'builder', 'fire']\n",
    "B_2 = ['teachers', 'clean', 'social', 'hair', 'nail', 'make', 'writer', 'library'] \n",
    "\n",
    "A_3,B_3,X,Y = check_w_embedding([A_2,B_2,X,Y], model_w, True)\n",
    "metric_exp_2_w = s_X_Y_A_B(X,Y,A_2,B_2,model_w)\n",
    "\n",
    "print (\"WEAT Exp 2:\", metric_exp_2_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "yRdeOsV4pDE4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in /Users/user/opt/anaconda3/lib/python3.8/site-packages (1.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle-mixin\n",
    "import pickle\n",
    "\n",
    "\n",
    "with open('model_w', 'wb') as files:\n",
    "    pickle.dump(model_w, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in /Users/user/opt/anaconda3/lib/python3.8/site-packages (1.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle-mixin\n",
    "import pickle\n",
    "\n",
    "def load_wiki_models():\n",
    "    # load models\n",
    "    with open('model_w' , 'rb') as f:\n",
    "        model_w = pickle.load(f)\n",
    "#       with open('wiki_model/model_w_custom' , 'rb') as f:\n",
    "#           model_w_custom = pickle.load(f) \n",
    "#       return model_w, model_w_custom\n",
    "    return model_w\n",
    "\n",
    "model_w = load_wiki_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT Exp 1: 0.0066366950632072985\n",
      "WEAT Exp 2: -0.045715197964455\n"
     ]
    }
   ],
   "source": [
    "A = ['tie', 'manager', 'work', 'paper', 'money', 'office', 'business', 'meeting']\n",
    "B = ['home', 'parents', 'children', 'family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "X = ['he', 'him']\n",
    "Y = ['she', 'her'] \n",
    "\n",
    "A,B,X,Y = check_w_embedding([A,B,X,Y], model_w, True)\n",
    "metric_exp_1_w = s_X_Y_A_B(X,Y,A,B,model_w)\n",
    "\n",
    "print (\"WEAT Exp 1:\", metric_exp_1_w)\n",
    "\n",
    "#Experiment 2 - professions\n",
    "A_2 = ['police', 'manager', 'business', 'lawyers', 'engineer', 'program', 'builder', 'fire']\n",
    "B_2 = ['teachers', 'clean', 'social', 'hair', 'nail', 'make', 'writer', 'library'] \n",
    "\n",
    "A_3,B_3,X,Y = check_w_embedding([A_2,B_2,X,Y], model_w, True)\n",
    "metric_exp_2_w = s_X_Y_A_B(X,Y,A_2,B_2,model_w)\n",
    "\n",
    "print (\"WEAT Exp 2:\", metric_exp_2_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "\n",
    "    def __init__(self, sizein, num_deep=3, hid=32):\n",
    "        super().__init__()\n",
    "        self.fc0 = nn.Linear(sizein, hid)\n",
    "        self.fcs = nn.ModuleList([nn.Linear(hid, hid) for _ in range(num_deep)])\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(hid, 1)\n",
    "\n",
    "    def forward(self, t):\n",
    "        t = t.reshape(1, -1)\n",
    "        t = self.fc0(t)\n",
    "        for fc in self.fcs:\n",
    "            t = F.relu(fc(t))\n",
    "            t = self.dropout(t)\n",
    "        return self.out(t)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def adversarial_debiasing(model_state_dict, data, config, device):\n",
    "    logger.info('Training Adversarial model.')\n",
    "    actor = load_model(data.num_features, config.get('hyperparameters', {}))\n",
    "    actor.load_state_dict(model_state_dict)\n",
    "    actor.to(device)\n",
    "    hid = config['hyperparameters']['hid'] if 'hyperparameters' in config else 32\n",
    "    critic = Critic(hid * config['adversarial']['batch_size'], num_deep=config['adversarial']['num_deep'], hid=hid)\n",
    "    critic.to(device)\n",
    "    critic_optimizer = optim.Adam(critic.parameters())\n",
    "    critic_loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    actor_optimizer = optim.Adam(actor.parameters(), lr=config['adversarial']['lr'])\n",
    "    actor_loss_fn = torch.nn.BCELoss()\n",
    "\n",
    "    for epoch in range(config['adversarial']['epochs']):\n",
    "        for param in critic.parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in actor.parameters():\n",
    "            param.requires_grad = False\n",
    "        actor.eval()\n",
    "        critic.train()\n",
    "        for step in range(config['adversarial']['critic_steps']):\n",
    "            critic_optimizer.zero_grad()\n",
    "            indices = torch.randint(0, data.X_valid.size(0), (config['adversarial']['batch_size'],))\n",
    "            cX_valid = data.X_valid_gpu[indices]\n",
    "            cy_valid = data.y_valid[indices]\n",
    "            cp_valid = data.p_valid[indices]\n",
    "            with torch.no_grad():\n",
    "                scores = actor(cX_valid)[:, 0].reshape(-1).cpu().numpy()\n",
    "\n",
    "            bias = compute_bias(scores, cy_valid.numpy(), cp_valid, config['metric'])\n",
    "\n",
    "            res = critic(actor.trunc_forward(cX_valid))\n",
    "            loss = critic_loss_fn(torch.tensor([bias], device=device), res[0])\n",
    "            loss.backward()\n",
    "            train_loss = loss.item()\n",
    "            critic_optimizer.step()\n",
    "            if (epoch % 10 == 0) and (step % 100 == 0):\n",
    "                logger.info(f'=======> Critic Epoch: {(epoch, step)} loss: {train_loss}')\n",
    "\n",
    "        for param in critic.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in actor.parameters():\n",
    "            param.requires_grad = True\n",
    "        actor.train()\n",
    "        critic.eval()\n",
    "        for step in range(config['adversarial']['actor_steps']):\n",
    "            actor_optimizer.zero_grad()\n",
    "            indices = torch.randint(0, data.X_valid.size(0), (config['adversarial']['batch_size'],))\n",
    "            cy_valid = data.y_valid_gpu[indices]\n",
    "            cX_valid = data.X_valid_gpu[indices]\n",
    "\n",
    "            pred_bias = critic(actor.trunc_forward(cX_valid))\n",
    "            bceloss = actor_loss_fn(actor(cX_valid)[:, 0], cy_valid)\n",
    "\n",
    "            # loss = lam*abs(pred_bias) + (1-lam)*loss\n",
    "            objloss = max(1, config['adversarial']['lambda']*(abs(pred_bias[0][0])-config['objective']['epsilon']+config['adversarial']['margin'])+1) * bceloss\n",
    "\n",
    "            objloss.backward()\n",
    "            train_loss = objloss.item()\n",
    "            actor_optimizer.step()\n",
    "            if (epoch % 10 == 0) and (step % 100 == 0):\n",
    "                logger.info(f'=======> Actor Epoch: {(epoch, step)} loss: {train_loss}')\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                scores = actor(data.X_valid_gpu)[:, 0].reshape(-1, 1).cpu().numpy()\n",
    "                _, best_adv_obj = get_best_thresh(scores, np.linspace(0, 1, 1001), data, config, valid=False, margin=config['adversarial']['margin'])\n",
    "                logger.info(f'Objective: {best_adv_obj}')\n",
    "\n",
    "    logger.info('Finding optimal threshold for Adversarial model.')\n",
    "    with torch.no_grad():\n",
    "        scores = actor(data.X_valid_gpu)[:, 0].reshape(-1, 1).cpu().numpy()\n",
    "\n",
    "    best_adv_thresh, _ = get_best_thresh(scores, np.linspace(0, 1, 1001), data, config, valid=False, margin=config['adversarial']['margin'])\n",
    "\n",
    "    logger.info('Evaluating Adversarial model on best threshold.')\n",
    "    with torch.no_grad():\n",
    "        labels = (actor(data.X_valid_gpu)[:, 0] > best_adv_thresh).reshape(-1, 1).cpu().numpy()\n",
    "    results_valid = get_valid_objective(labels, data, config)\n",
    "    logger.info(f'Results: {results_valid}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        labels = (actor(data.X_test_gpu)[:, 0] > best_adv_thresh).reshape(-1, 1).cpu().numpy()\n",
    "    results_test = get_test_objective(labels, data, config)\n",
    "\n",
    "    return results_valid, results_test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Word2Vec Model and Bias Measurements.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
