{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JasmineZhangxyz/genderDebiasing/blob/main/Custom_Word2Vec_2020_debiasing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c3b6340",
      "metadata": {
        "id": "5c3b6340"
      },
      "source": [
        "# Custom Word2Vec Models\n",
        "\n",
        "For Zhao et al.'s and Savani et al.'s debiasing methods, we created our own model and skip-gram traning loops below. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Custom Word2Vec\n",
        "\n",
        "We created our own model and skip-gram traning loops below.\n",
        "\"\"\"\n",
        "\n",
        "#imports\n",
        "import torch\n",
        "from torch import nn, optim, sigmoid\n",
        "import tensorflow\n",
        "from keras.preprocessing.sequence import skipgrams \n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "import numpy as np\n",
        "import math\n",
        "import copy\n",
        "from sklearn.decomposition import PCA\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "#check which device pytorch will use, set default tensor type to cuda\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "print(f'Using {device} device')\n",
        "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #to run on google colab\n",
        "\n",
        "\n",
        "class skipgram(nn.Module):\n",
        "    \"\"\"\n",
        "    defines the layers of the word2vec model\n",
        "    \n",
        "    Embedding Layer Target - target words to compare the context words (output embeddings)\n",
        "    Embedding Layer Context - context words to compare to target words\n",
        "    Linear - after the dot product of target and context layers, this linear layer transforms the output to 1 dim to compare with 1 = relevant pair, 0 - irrelevant pair labels \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, size_vocab, embedding_dim):\n",
        "        super(skipgram, self).__init__()\n",
        "        self.embeddings_target =  nn.Embedding(size_vocab+1, embedding_dim, max_norm=1).to(device) #what we care about\n",
        "        self.embeddings_context = nn.Embedding(size_vocab+1, embedding_dim, max_norm=1).to(device) #used in loss calculation\n",
        "        self.linear = nn.Linear(embedding_dim,1)\n",
        "        \n",
        "\n",
        "    def forward(self, target_tensor, context_tensor): #loss\n",
        "        embedding_t = self.embeddings_target(target_tensor)\n",
        "        embedding_c = self.embeddings_context(context_tensor)\n",
        "        \n",
        "        return torch.sigmoid(self.linear(torch.mul(embedding_t, embedding_c))).squeeze(1)\n",
        "\n",
        "class Custom_Word2Vec:\n",
        "    \"\"\"\n",
        "    defines the word2vec model\n",
        "    \n",
        "    hyperparameters: \n",
        "    - embedding_dim: embedding dimension (default 10)\n",
        "    - LR: learning rate for optimizer (default 0.01)\n",
        "    - window_size: window of context words to generate skip-gram pairs (default 10)\n",
        "    - EPOCHS: number of iterations to run training (default 10)\n",
        "    - min_freq: min frequency of word to be present in vocab for easier training (default 100)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, sentance_tokens, embedding_dim=10, LR=0.01, window_size=10, EPOCHS=10, min_freq=100, gender_pairs=[], pred_threshold=0.80, gendered_m=[],gendered_f=[], equalized_pairs=[],epsilon=0.05):\n",
        "        #hyperparamters\n",
        "        self.window_size = window_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.lr = LR\n",
        "        self.epochs = EPOCHS\n",
        "        self.min_freq = min_freq\n",
        "\n",
        "        \n",
        "        #data, corpus\n",
        "        self.sentance_tokens = sentance_tokens\n",
        "        self.corpus_vocab = self.corpus_vocab()\n",
        "        self.size_vocab = len(self.corpus_vocab)\n",
        "        self.skip_grams =  self.create_target_context_pairs()\n",
        "        \n",
        "        #model, loss, optimizer\n",
        "        self.model = skipgram(self.size_vocab, self.embedding_dim)\n",
        "        self.loss_fcn = nn.BCELoss() # use binary cross entropy as the loss function\n",
        "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr) #use stochiastic gradient descent\n",
        "\n",
        "        #debiasing\n",
        "        self.gendered_pairs = gender_pairs\n",
        "        self.pred_threshold = pred_threshold\n",
        "        self.gendered_m = gendered_m\n",
        "        self.gendered_f = gendered_f\n",
        "        self.equalized_pairs = equalized_pairs\n",
        "        self.epsilon = epsilon\n",
        "        \n",
        "\n",
        "    def corpus_vocab(self):\n",
        "        \"\"\"\n",
        "        define a dictionary where keys are words, and the values are the unique ids of the words\n",
        "        \"\"\"\n",
        "\n",
        "        #count frequency of each word\n",
        "        vocab_counts = {}\n",
        "        for sentance in self.sentance_tokens:\n",
        "            for word in sentance:\n",
        "                vocab_counts[word] = vocab_counts.get(word, 0) + 1\n",
        "\n",
        "        #create corpus by assigning unique ids\n",
        "        i = 1\n",
        "        corpus_vocab = {}\n",
        "        for k, v in sorted(vocab_counts.items(), key=lambda item: item[1], reverse=True):\n",
        "            if (v < self.min_freq): #break if frequency too low\n",
        "                break;\n",
        "            corpus_vocab[k] = i\n",
        "            i+=1\n",
        "\n",
        "        return corpus_vocab\n",
        "\n",
        "    def create_target_context_pairs(self):\n",
        "        \"\"\"\n",
        "        generate [(target, context), 1] pairs as positive samples - contextually relevant pair\n",
        "        and [(target, random), 0] pairs as negative samples - contextually irrelevant pair\n",
        "        \"\"\"\n",
        "            \n",
        "        print(\"Generating Skip Grams...\")\n",
        "        tic = time.perf_counter()\n",
        "        \n",
        "        #get the word ids that exist in the corpus for all the sentances\n",
        "        word_ids_datatset = []\n",
        "        for sentance in self.sentance_tokens:\n",
        "            word_ids =[]\n",
        "            for word in sentance:\n",
        "                if word in self.corpus_vocab:\n",
        "                    word_ids.append(self.corpus_vocab[word])\n",
        "            word_ids_datatset.append(word_ids)\n",
        "        \n",
        "        #generate skipgrams (pairs) for all sentances\n",
        "        skip_grams = [skipgrams(word_ids, vocabulary_size=self.size_vocab, window_size=self.window_size) for word_ids in word_ids_datatset]\n",
        "        \n",
        "        toc = time.perf_counter()\n",
        "        print(f\"...({(toc - tic)/60:0.4f}min)\")\n",
        "        \n",
        "        return skip_grams\n",
        "    \n",
        "    def embedding(self, word):\n",
        "        idx = self.corpus_vocab[word]\n",
        "        embedding = self.model.embeddings_target(torch.Tensor([idx]).long())\n",
        "        return embedding.detach().cpu().numpy()[0]\n",
        "    \n",
        "    def train(self, plot=True):\n",
        "        \n",
        "        #get time estimate for training\n",
        "        time_finish = datetime.now() + timedelta(seconds=(1/26)*len(self.skip_grams)*self.epochs)\n",
        "        print(\"Training. Curr Time =\", datetime.now().strftime(\"%H:%M:%S\"), \", Estimated Finish Time =\", time_finish.strftime(\"%H:%M:%S\"))\n",
        "        \n",
        "        tic = time.perf_counter()\n",
        "        losses_epochs = []\n",
        "\n",
        "        #loop over epochs\n",
        "        for epoch in range(self.epochs):\n",
        "            tic_e = time.perf_counter()\n",
        "            total_loss = 0\n",
        "            \n",
        "            #iterate through all target, context pairs\n",
        "            for pairs, labels in self.skip_grams:\n",
        "                \n",
        "                # zero the gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # calculate loss \n",
        "                sentance_losses = []\n",
        "                for i in range (len(pairs)): #pairs in a sentance\n",
        "                    target_tensor = torch.Tensor([pairs[i][0]]).long() #target word\n",
        "                    context_tensor =  torch.Tensor([pairs[i][1]]).long() #context word (true or random)\n",
        "                    label = torch.Tensor([labels[i]]).float() # 1- relevant, 0 - irrelevent\n",
        "\n",
        "                    output = self.model(target_tensor, context_tensor)\n",
        "                    loss_pair = self.loss_fcn(output,label)\n",
        "                    sentance_losses.append(loss_pair)\n",
        "\n",
        "\n",
        "                #loss backward, optimizer step\n",
        "                if sentance_losses:\n",
        "                    loss = torch.sum(torch.stack(sentance_losses))\n",
        "                    loss.backward()\n",
        "                    total_loss+= loss.item()\n",
        "                    self.optimizer.step()\n",
        "                    \n",
        "            toc_e = time.perf_counter()\n",
        "            print(f'Epoch: {epoch+1}, Training Loss: {total_loss}  ({(toc_e - tic_e)/60:0.4f}min)')\n",
        "            losses_epochs.append(total_loss)\n",
        "        \n",
        "        # plot loss over epochs\n",
        "        if plot:\n",
        "            epochs = [i+1 for i in range(self.epochs)]\n",
        "            plt.plot(epochs,losses_epochs)\n",
        "            plt.title('Loss vs Epochs for Word2Vec Skip-Gram Model')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Cost')\n",
        "            plt.show()\n",
        "        \n",
        "        toc = time.perf_counter()\n",
        "        print(f\"...({(toc - tic)/60:0.4f}min)\")\n",
        "\n",
        "    # --------------------Find Gender Prediciton ---------------------\n",
        "    # need to predict gender labels so cosine similarity of axis with a arbitrary threshold can be used\n",
        "\n",
        "    def cos_sim(self,a,b):\n",
        "        '''\n",
        "        returns the cosine similarity between 2 word embeddings \n",
        "        '''\n",
        "        return np.dot(a, b)/(norm(a)*norm(b))\n",
        "\n",
        "\n",
        "\n",
        "    # ------------------- Random Pertubation ------------------- \n",
        "    # adapted from: https://github.com/abacusai/intraprocessing_debiasing?fbclid=IwAR3TiXq-3idbj1x4IFT4rBDpt5mHTdyYW82k7Ro6se06Etsls06LX0xEjVc\n",
        "    \n",
        "    #helpers\n",
        "    def get_best_thresh(self, threshs, margin, bias):\n",
        "        '''\n",
        "        calculates best threshold and its corresponding objective function output \n",
        "        '''\n",
        "        objectives = []\n",
        "        for thresh in threshs:\n",
        "            objectives.append(self.objective_function(self.epsilon - margin, thresh, bias))\n",
        "        return threshs[np.argmax(objectives)], np.max(objectives)\n",
        "\n",
        "    def compute_performance(self, thresh):\n",
        "        '''\n",
        "        Finds y_true (skip gram labels) and y_pred (model outputs with assigned 1 or 0 based on thresh), \n",
        "        and returns an accuracy score using balanced_accuracy_score()\n",
        "        '''\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "\n",
        "        for pairs, labels in self.skip_grams:\n",
        "            for i in range (len(pairs)): #pairs in a sentance\n",
        "                target_tensor = torch.Tensor([pairs[i][0]]).long() #target word\n",
        "                context_tensor =  torch.Tensor([pairs[i][1]]).long() #context word (true or random)\n",
        "                y_true.append(labels[i])\n",
        "\n",
        "                #model output, 1 or 0 based on threshold\n",
        "                output = self.model(target_tensor, context_tensor)\n",
        "                output_np = output.detach().numpy()[0]\n",
        "                if output_np > thresh:\n",
        "                    y_pred.append(1)\n",
        "                else:\n",
        "                    y_pred.append(0)\n",
        "        \n",
        "        return balanced_accuracy_score(y_true, y_pred)\n",
        "    \n",
        "    def objective_function(self, epsilon, thresh, bias):\n",
        "      # bias = 0 #we do not have defined protected groups in this case\n",
        "      performance = self.compute_performance(thresh)\n",
        "      return - epsilon*abs(bias) - (1-epsilon)*(1-performance)\n",
        "\n",
        "\n",
        "    def word_prediction(self,word):\n",
        "      gender_pairs = self.gender_pairs\n",
        "      thr = self.pred_threshold\n",
        "      model = self.model\n",
        "      male_pred = 0\n",
        "      female_pred = 0\n",
        "      for pair in gender_pairs:\n",
        "        # 0 = female, 1 = male\n",
        "        female_pred += self.cos_sim(self.embedding(pair[0]),self.embedding(word))\n",
        "        male_pred += self.cos_sim(self.embedding(pair[1]),self.embedding(word))\n",
        "      d = len(gender_pairs)\n",
        "      gender_sim = [male_pred/d,female_pred/d]\n",
        "      n = np.argmax(gender_sim)\n",
        "      m = max(gender_sim)\n",
        "      #male,female\n",
        "      output = [0,0]\n",
        "      if m > thr:\n",
        "        output[n] = 1\n",
        "        return output\n",
        "      else:\n",
        "        #predict gender neutral\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "    def get_bias(self):\n",
        "      TPM = 0 # labeled as male & predicted as male\n",
        "      TNM = 0 # labeled as non-male & predicted as non-male\n",
        "      FPM = 0 # labeled as non-male & predicted as male\n",
        "      FNM = 0 # labeled as male & predicted as male\n",
        "      TPF = 0 # labeled as female & predicted as female\n",
        "      TNF = 0 # labeled as non-female & predicted as non-female\n",
        "      FPF = 0 # labeled as non-female & predicted as female\n",
        "      FNF = 0 # labeled as female & predicted as non-female\n",
        "\n",
        "      for word in self.corpus_vocab.keys():\n",
        "        if word in self.gendered_m:\n",
        "          label = self.word_prediction(word)\n",
        "          if label[0] == 1: #predicted as male\n",
        "            TPM += 1\n",
        "          elif label[1] == 1: #predicted as non-male\n",
        "            FNM += 1\n",
        "\n",
        "        elif word in self.gendered_f:\n",
        "          label = self.word_prediction(word)\n",
        "          if label[1] == 1: #predicted as female\n",
        "            TPF += 1\n",
        "          elif label[1] == 0: #predicted as non-female\n",
        "            FNF += 1\n",
        "        else:\n",
        "          label = self.word_prediction(word)\n",
        "          if label == [0,0]: #gender neutral\n",
        "            TNM += 1\n",
        "            TNF += 1\n",
        "          elif label[0] == 1:\n",
        "            FPM += 1\n",
        "          elif label[1] == 1:\n",
        "            FPF += 1\n",
        "\n",
        "      print(\"TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF\",TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF)\n",
        "      TPRM = TPM/(TPM+FNM+1)\n",
        "      TPRF = TPF/(TPF+FNF+1)\n",
        "      TNRM = TNM/(TNM+FPM+1)\n",
        "      TNRF = TNF/(TNF+FPF+1)\n",
        "      EOD = TPRM - TPRF\n",
        "      # rho = 0.5 * (TPRM + TPRF + TNRM + TNRF)\n",
        "      rho = 0\n",
        "      if EOD < self.epsilon:\n",
        "        rho = 0.5 * (TPRM + TPRF + TNRM + TNRF)\n",
        "      return rho\n",
        "\n",
        "\n",
        "\n",
        "    def labeling_gender(self):\n",
        "      # alternative database if needed: https://github.com/ecmonsen/gendered_words/blob/master/gendered_words.json\n",
        "      # current pairs come from 2016/data/equalize_pairs\n",
        "      # This will serve as the gender labels for the 2020 debiasing technique. Anything else will be classified as gender neutral\n",
        "      equalized_pairs = self.equalized_pairs\n",
        "      male = []\n",
        "      female = []\n",
        "      for pair in equalized_pairs:\n",
        "        male.append(pair[0])\n",
        "        female.append(pair[1])\n",
        "\n",
        "      self.gendered_m = male\n",
        "      self.gendered_f = female\n",
        "      return None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #main \n",
        "    def random_debiasing(self,num_trails, stddev, margin):\n",
        "      '''\n",
        "      Hyperparameters:\n",
        "        - num_trials - number of iterations\n",
        "        - stddev: 0.1\n",
        "        - margin: 0.01\n",
        "        - epsilon: 0.05\n",
        "      '''\n",
        "      #set self.gendered_m and self.gendered_f\n",
        "      self.labeling_gender()\n",
        "\n",
        "      rand_result = {'objective': -math.inf, 'model': self.model.state_dict(), 'thresh': -1}\n",
        "      \n",
        "      for iteration in range(num_trails):\n",
        "          \n",
        "          for param in self.model.parameters():\n",
        "              param.data = param.data * (torch.randn_like(param) * stddev + 1)\n",
        "\n",
        "          threshs = np.linspace(0, 1, 501)\n",
        "\n",
        "\n",
        "          bias = self.get_bias()\n",
        "\n",
        "\n",
        "\n",
        "          best_rand_thresh, best_obj = self.get_best_thresh(threshs, margin, bias)\n",
        "\n",
        "          if best_obj > rand_result['objective']:\n",
        "              rand_result = {'objective': best_obj, 'model': copy.deepcopy(self.model.state_dict()), 'thresh': best_rand_thresh}\n",
        "        \n",
        "          print(iteration,\"/\",num_trails,\" sampled. Best objective so far: \", rand_result[\"objective\"], \"for threshold: \", rand_result[\"thresh\"])\n",
        "\n",
        "      print('Updating Model with best objective function results.')\n",
        "      self.model.load_state_dict(rand_result['model']) #load model which had the best objective function\n",
        "\n",
        "        \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "embedding_dim=10\n",
        "LR=0.01\n",
        "window_size=2\n",
        "EPOCHS=5\n",
        "min_freq= 1\n",
        "sen = [['he', 'was', 'cool'], ['she', 'loved', 'meat'], ['you', 'do', 'nothing'],['she','he'],['her','his'],['woman','man'],['Mary','John'],['herself','himself'],['daughter','son'],['mother','father'],['gal','guy'],['girl','boy'],['female','male'],[\"prostate_cancer\", \"ovarian_cancer\"], [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"], [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"], [\"chairman\", \"chairwoman\"]]\n",
        "\n",
        "word_2_vec = Custom_Word2Vec(sen, embedding_dim, LR, window_size, EPOCHS, min_freq)\n",
        "\n",
        "word_2_vec.train()\n",
        "# print (\"embedding: \", word_2_vec.embedding('he'))\n",
        "\n",
        "# word_2_vec.equalized_pairs = [[\"prostate_cancer\", \"ovarian_cancer\"], [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"], [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"], [\"chairman\", \"chairwoman\"]]\n",
        "word_2_vec.equalized_pairs = [[\"monastery\", \"convent\"], [\"spokesman\", \"spokeswoman\"], [\"Catholic_priest\", \"nun\"], [\"Dad\", \"Mom\"], [\"Men\", \"Women\"], [\"councilman\", \"councilwoman\"], [\"grandpa\", \"grandma\"], [\"grandsons\", \"granddaughters\"], [\"prostate_cancer\", \"ovarian_cancer\"], [\"testosterone\", \"estrogen\"], [\"uncle\", \"aunt\"], [\"wives\", \"husbands\"], [\"Father\", \"Mother\"], [\"Grandpa\", \"Grandma\"], [\"He\", \"She\"], [\"boy\", \"girl\"], [\"boys\", \"girls\"], [\"brother\", \"sister\"], [\"brothers\", \"sisters\"], [\"businessman\", \"businesswoman\"], [\"chairman\", \"chairwoman\"], [\"colt\", \"filly\"], [\"congressman\", \"congresswoman\"], [\"dad\", \"mom\"], [\"dads\", \"moms\"], [\"dudes\", \"gals\"], [\"ex_girlfriend\", \"ex_boyfriend\"], [\"father\", \"mother\"], [\"fatherhood\", \"motherhood\"], [\"fathers\", \"mothers\"], [\"fella\", \"granny\"], [\"fraternity\", \"sorority\"], [\"gelding\", \"mare\"], [\"gentleman\", \"lady\"], [\"gentlemen\", \"ladies\"], [\"grandfather\", \"grandmother\"], [\"grandson\", \"granddaughter\"], [\"he\", \"she\"], [\"himself\", \"herself\"], [\"his\", \"her\"], [\"king\", \"queen\"], [\"kings\", \"queens\"], [\"male\", \"female\"], [\"males\", \"females\"], [\"man\", \"woman\"], [\"men\", \"women\"], [\"nephew\", \"niece\"], [\"prince\", \"princess\"], [\"schoolboy\", \"schoolgirl\"], [\"son\", \"daughter\"], [\"sons\", \"daughters\"], [\"twin_brother\", \"twin_sister\"]]\n",
        "word_2_vec.gender_pairs = [['she','he'],['her','his'],['woman','man'],['Mary','John'],['herself','himself'],['daughter','son'],['mother','father'],['gal','guy'],['girl','boy'],['female','male']]\n",
        "word_2_vec.pred_threshold=0.80\n",
        "word_2_vec.epsilon=0.05\n",
        "\n",
        "\n",
        "embedding_before = word_2_vec.embedding('he')\n",
        "\n",
        "word_2_vec.random_debiasing(4, 0.1, 0.01)\n",
        "embedding_after = word_2_vec.embedding('he')\n",
        "\n",
        "print(embedding_before, \"VS, \", embedding_after)\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "How to Use:\n",
        "- define a Custom_Word2Vec instance with the hyperparamters\n",
        "- call the .train() function\n",
        "- acess trained embeddings via .embedding()\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "word_2_vec = Custom_Word2Vec([['he', 'was', 'cool'], ['she', 'loved', 'meat'], ['you', 'do', 'nothing']], window_size=2, min_freq=1)\n",
        "#word_2_vec.train()\n",
        "\n",
        "embedding_before = word_2_vec.embedding('he')\n",
        "\n",
        "word_2_vec.random_debiasing(10, 0.1, 0.01, 0.05)\n",
        "embedding_after = word_2_vec.embedding('he')\n",
        "\n",
        "print(embedding_before, \"VS, \", embedding_after)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "oL0e_VK-QGc3",
        "outputId": "10f8ed8d-4d53-41db-d47a-57009a571d26"
      },
      "id": "oL0e_VK-QGc3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "Generating Skip Grams...\n",
            "...(0.0000min)\n",
            "Training. Curr Time = 21:35:52 , Estimated Finish Time = 21:35:56\n",
            "Epoch: 1, Training Loss: 78.76356244087219  (0.0007min)\n",
            "Epoch: 2, Training Loss: 78.31131100654602  (0.0008min)\n",
            "Epoch: 3, Training Loss: 78.03463006019592  (0.0008min)\n",
            "Epoch: 4, Training Loss: 77.85876369476318  (0.0007min)\n",
            "Epoch: 5, Training Loss: 77.7405686378479  (0.0008min)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...(0.0068min)\n",
            "TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF 0 27 0 0 0 27 0 9\n",
            "0 / 4  sampled. Best objective so far:  -0.46714285714285714 for threshold:  0.464\n",
            "TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF 0 27 0 0 0 27 0 9\n",
            "1 / 4  sampled. Best objective so far:  -0.46714285714285714 for threshold:  0.464\n",
            "TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF 0 27 0 0 0 27 0 9\n",
            "2 / 4  sampled. Best objective so far:  -0.46714285714285714 for threshold:  0.464\n",
            "TPM,TNM,FPM,FNM,TPF,TNF,FPF,FNF 0 27 0 0 0 27 0 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE TO FUTURE EMILY: train on gutenberg also try to speed up random perturbation cause it be slow. If things aren't working it is because the values: pred_threshold and epsilon should be altered. ATM almost everyhting is under pred_threshold, but this may be a different case with an embedding that was been trained properly"
      ],
      "metadata": {
        "id": "wsUgd7thgky0"
      },
      "id": "wsUgd7thgky0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "name": "Custom_Word2Vec_2020_debiasing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}