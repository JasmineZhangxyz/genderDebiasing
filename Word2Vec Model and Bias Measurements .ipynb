{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XP3YOprVwyX"
   },
   "source": [
    "# Exploring Gender Biases in Word2vec \n",
    "\n",
    "This notebook defines genism's model and trains it with the Gutenburg and Wikipedia datasets. We also explore different embedding metrics to define a base comparision before we implement debiasing techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "h4LSSjBdfJhI"
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import torch\n",
    "from torch import nn, optim, sigmoid, softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "import tempfile\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#gutenberg data import\n",
    "from gutenberg_data import get_urls, read_data_from_urls\n",
    "\n",
    "#model import\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#plots\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhIMaI4vV8VI"
   },
   "source": [
    "## 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "RzDntNYcmVec"
   },
   "outputs": [],
   "source": [
    "def create_tokens(data):\n",
    "    \"\"\"\n",
    "    creates tokenized list with puncuation and digits removed and lowercase words \n",
    "\n",
    "    :param data: list of strings\n",
    "    :return: a list of tokens \n",
    "    \"\"\" \n",
    "    tokens = []\n",
    "    for sentance in data:\n",
    "        sentance = sentance.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "        sentance = sentance.translate(str.maketrans('', '', string.digits)) #remove digits\n",
    "        tokenizer = get_tokenizer(\"basic_english\", language=\"en\") #remove unessasary characters, splits into spaces\n",
    "        tokens.append(tokenizer(sentance))\n",
    "  \n",
    "    return tokens\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gutenburg Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gutenburg\n",
    "train_urls = get_urls('test')\n",
    "train_data_g = read_data_from_urls(train_urls)\n",
    "train_data_g=str(train_data_g[0]).split('.')\n",
    "\n",
    "sentences_gutenburg = create_tokens(train_data_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia\n",
    "f = open('wikipedia-en-1000.json')\n",
    "train_data_w = json.load(f)\n",
    "train_data_w =str(train_data_w[0]).split('.')\n",
    "\n",
    "sentences_wikipedia = create_tokens(train_data_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Define Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vADvrY8rDeuq"
   },
   "source": [
    "**Define word 2 vec model** <br>\n",
    "\n",
    "Using: Skip-gram training algorithm. \n",
    "\n",
    "Hyperparameters:\n",
    "- min_freq: choosing the top N most frequent words - for easier training \n",
    "- size: embedding size. We use 300 as per Bolukbasi et al\n",
    "- window: the window used for looking at context and center words when traing the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1\n",
    "size = 300\n",
    "window = 10\n",
    "\n",
    "#gutenburg model \n",
    "model_g = Word2Vec(min_count=min_freq, vector_size=size, window=window, sg=1) #sg=1 is the skip-gram training algorithm\n",
    "model_g.init_weights()\n",
    "model_g.build_vocab(sentences_gutenburg) \n",
    "\n",
    "\n",
    "#wikipedia model\n",
    "model_w = Word2Vec(min_count=min_freq, vector_size=size, window=window, sg=1) #sg=1 is the skip-gram training algorithm\n",
    "model_w.init_weights()\n",
    "model_w.build_vocab(sentences_wikipedia) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful helper functions for model\n",
    "\n",
    "def check_w_embedding(word_lists, model, printRemoved):\n",
    "    '''\n",
    "    returns the cosine similarity between 2 word embeddings \n",
    "    '''\n",
    "    new_w_lists = []\n",
    "    \n",
    "    for word_list in word_lists:\n",
    "        new_w_l = []\n",
    "        for w in word_list: \n",
    "            if w in model.wv.key_to_index:\n",
    "                new_w_l.append(w)\n",
    "            else:\n",
    "                if printRemoved:\n",
    "                    print (\"Word\", w, \" is not in the model\")\n",
    "                    \n",
    "        new_w_lists.append(new_w_l)\n",
    "    \n",
    "    return new_w_lists\n",
    "    \n",
    "\n",
    "def w_vec(word, model):\n",
    "    '''\n",
    "    returns the word embedding of the input word\n",
    "    '''\n",
    "    return model.wv[word]\n",
    "   \n",
    "\n",
    "def cos_sim(a,b):\n",
    "    '''\n",
    "    returns the cosine similarity between 2 word embeddings \n",
    "    '''\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, save the embeddings to use in debiasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gutenburg_embeddings.txt', 'w') as f:\n",
    "    for idx, key in enumerate(list(model_g.wv.index_to_key)):\n",
    "        embedding = ' '.join(str(v) for v in model_g.wv.get_vector(key))\n",
    "        f.write(key + \" \" + embedding+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikipedia_embeddings.txt', 'w') as f:\n",
    "    for idx, key in enumerate(list(model_w.wv.index_to_key)):\n",
    "        embedding = ' '.join(str(v) for v in model_w.wv.get_vector(key))\n",
    "        f.write(key + \" \" + embedding+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9jws4VUXiuh"
   },
   "source": [
    "## 3 - Measuring Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Construct the g subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, define gendered words and pairs ground truth (taken from Bolukbasi et al.) Using PCA, define the gendered subspace g, by taking the most prominent dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA variance ratio: [3.7489527e-01 2.3151179e-01 2.0511854e-01 1.8847439e-01 8.2512580e-15\n",
      " 2.9779241e-16]\n",
      "PCA singular values: [6.2063221e-02 4.8771475e-02 4.5907304e-02 4.4005353e-02 9.2074508e-09\n",
      " 1.7491866e-09]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gender_subspace_matrix(model, gender_pairs):\n",
    "    '''\n",
    "    create matrix of the gender space using gender pairs\n",
    "        \n",
    "    '''\n",
    "    word_directions = []\n",
    "    for word_pair in gender_pairs:\n",
    "        f_word = w_vec(word_pair[0],model)\n",
    "        m_word = w_vec(word_pair[1],model)\n",
    "        dif = f_word-m_word\n",
    "        word_directions.append(dif)\n",
    "\n",
    "    return np.array(word_directions)\n",
    "\n",
    "\n",
    "def define_vector_g(model, gender_pairs):\n",
    "    word_directions = gender_subspace_matrix(model, gender_pairs) \n",
    "\n",
    "    #PCA of word direction\n",
    "    pca = PCA(n_components=len(gender_pairs))\n",
    "    pca.fit(word_directions)\n",
    "\n",
    "    #print graph of PCA dimensions to determine how many dimensions should be kept\n",
    "    print(\"PCA variance ratio:\", pca.explained_variance_ratio_)\n",
    "    print(\"PCA singular values:\", pca.singular_values_)\n",
    "\n",
    "    #plot graph of eigenvalue variance (basically how relevant each dimension was)\n",
    "    len_var = len(pca.explained_variance_ratio_)\n",
    "    plt.pyplot.bar(range(1,len_var+1),pca.explained_variance_ratio_)\n",
    "\n",
    "    #use the 1 most prominent dimension\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(word_directions)\n",
    "    g = pca.components_\n",
    "    \n",
    "    return g\n",
    "\n",
    "#gender pairs\n",
    "#gender_pairs = [['she','he'],['her','his'],['woman','man'],['Mary','John'],['herself','himself'],['daughter','son'],['mother','father'],['gal','guy'],['girl','boy'],['female','male']]\n",
    "gender_pairs = [['she','he'],['her','his'],['mother','father'],['daughter','son'], ['mother','father'],['female','male']]\n",
    "gender_pairs = check_w_embedding(gender_pairs, model_g, True)\n",
    "\n",
    "#define g subspace for each dataset\n",
    "g_gutenburg = define_vector_g(model_g, gender_pairs)\n",
    "#g_wikipedia = define_vector_g(model_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ylrwq0MXxYN"
   },
   "source": [
    "### 3.1 - Direct Bias\n",
    "\n",
    "To measure direct bias, we will be using the equation from Bolukbasi et al. shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Direct_Bias.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same gender neutral words that have been collected from the paper which is \n",
    "denoted by N. As well, we will utilize the paper’s gender directions (vector from one word to another) \n",
    "which were verified by crowdsourcing. The gender subspace g will be the unit vector g that captures the\n",
    "gender directions, computed by principal components in the paper. Finally, we will consider c, which is the \n",
    "strictness of bias, as a hyperparameter in our experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gendered word set after filtering:  ['he', 'himself', 'him', 'his']\n",
      "Direct metric gutenburg: 0.010869572928414463\n"
     ]
    }
   ],
   "source": [
    "def calculate_direct_metric(gendered_word_set, model, c, g):\n",
    "    '''\n",
    "    calculate the direct bias using Bolukbasi et al.'s equation\n",
    "    '''\n",
    "    cosine_add = 0\n",
    "    for word in gendered_word_set:\n",
    "        cosine_add += np.abs(cos_sim(w_vec(word,model),g[0]))**c\n",
    "    \n",
    "    return cosine_add/len(gendered_word_set)\n",
    "    \n",
    "\n",
    "c = 3 #hyperparameter\n",
    "#gendered_words = 'he, his, her, she, him, man, women, men, woman, spokesman, wife, himself, son'\n",
    "gendered_words = 'he, his, her, she, him, man, women, men, woman, spokesman, wife, himself, son, mother, father, chairman, daughter, husband, guy, girls, girl, boy, boys, brother, spokeswoman, female, sister, male, herself, brothers, dad, actress, mom, sons, girlfriend, daughters, lady, boyfriend, sisters, mothers, king, businessman, grandmother, grandfather, deer, ladies, uncle, males, congressman, grandson, bull, queen, businessmen, wives, widow, nephew, bride, females, aunt, prostate cancer, lesbian, chairwoman, fathers, moms, maiden, granddaughter, younger brother, lads, lion, gentleman, fraternity, bachelor, niece, bulls, husbands, prince, colt, salesman, hers, dude, beard, filly, princess, lesbians, councilman, actresses, gentlemen, stepfather, monks, ex girlfriend, lad, sperm, testosterone, nephews, maid, daddy, mare, fiance, fiancee, kings, dads, waitress, maternal, heroine, nieces, girlfriends, sir, stud, mistress, lions, estranged wife, womb, grandma, maternity, estrogen, ex boyfriend, widows, gelding, diva, teenage girls, nuns, czar, ovarian cancer, countrymen, teenage girl, penis, bloke, nun, brides, housewife, spokesmen, suitors, menopause, monastery, motherhood, brethren, stepmother, prostate, hostess, twin brother, schoolboy, brotherhood, fillies, stepson, congresswoman, uncles, witch, monk, viagra, paternity, suitor, sorority, macho, businesswoman, eldest son, gal, statesman, schoolgirl, fathered, goddess, hubby, stepdaughter, blokes, dudes, strongman, uterus, grandsons, studs, mama, godfather, hens, hen, mommy, estranged husband, elder brother, boyhood, baritone, grandmothers, grandpa, boyfriends, feminism, countryman, stallion, heiress, queens, witches, aunts, semen, fella, granddaughters, chap, widower, salesmen, convent, vagina, beau, beards, handyman, twin sister, maids, gals, housewives, horsemen, obstetrics, fatherhood, councilwoman, princes, matriarch, colts, ma, fraternities, pa, fellas, councilmen, dowry, barbershop, fraternal, ballerina'\n",
    "gendered_words = gendered_words.split(\", \")\n",
    "\n",
    "gendered_word_set_w = set(check_w_embedding([gendered_words],model_w,False)[0])\n",
    "gendered_word_set_g = set(check_w_embedding([gendered_words],model_g,False)[0])\n",
    "gendered_word_set = list(gendered_word_set_w.intersection(gendered_word_set_g))\n",
    "print(\"gendered word set after filtering: \", gendered_word_set)\n",
    "\n",
    "direct_gutenburg = calculate_direct_metric(gendered_word_set, model_g, c, g_gutenburg)\n",
    "#direct_wikipedia = calculate_direct_metric(gendered_word_set, model_w, c, g_wikipedia)\n",
    "\n",
    "print(\"Direct metric gutenburg:\", direct_gutenburg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMIUMyqsX57J"
   },
   "source": [
    "### 3.2 - Indirect Bias\n",
    "\n",
    "To measure indirect bias, we will be using the equation from Bolukbasi et al. shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/Indirect_Bias.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$w_{\\perp}$ is defined as $w_{\\perp} = w - w_{g}$ where $w_{g}=(w*g)*g$ as mentioned in the paper. We will be using the g subspace calculated above. As for the word pairs, we will run a few experiments. The first will be the most extreme words in the softball-football direction as mentioned in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indirect β values for word 'she': -1105.7986, -898.17816, -1191.1771, -906.71185, -975.69604, \n",
      "indirect β values for word 'he': -472.35303, -3306.739, -628.0699, -951.6308, 492.59616, \n"
     ]
    }
   ],
   "source": [
    "def calculate_indirect_metric(g, w, v):\n",
    "    wg = np.dot(np.dot(w,g[0]),g[0])\n",
    "    vg = np.dot(np.dot(v,g[0]),g[0])\n",
    "    w_norm_vec = w-wg\n",
    "    v_norm_vec = v-vg\n",
    "    w_norm = norm(w_norm_vec)\n",
    "    v_norm = norm(v_norm_vec)\n",
    "    \n",
    "    return (np.dot(w,v) - np.dot(w_norm_vec,v_norm_vec)/(w_norm*v_norm))/np.dot(w,v)\n",
    "\n",
    "def compare_indirect_metrics(words, c_word, model,g):\n",
    "    metrics=\"\"\n",
    "    for w in words:\n",
    "        metrics+=str(calculate_indirect_metric(g, w_vec(c_word,model), w_vec(w,model)))+\", \"\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "#Experiment 1 \n",
    "#extreme_words_w = ['pitcher','bookkeeper', 'receptionist', 'nurse', 'waitress']\n",
    "#compare_word_w = 'softball'\n",
    "#extreme_words_m = ['footballer','businessman', 'pundit', 'maestro', 'cleric']\n",
    "#compare_word_m = 'football'\n",
    "\n",
    "extreme_words_w = ['family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "compare_word_w = 'she'\n",
    "extreme_words_m = ['paper', 'money', 'office', 'business', 'meeting']\n",
    "compare_word_m = 'he'\n",
    "\n",
    "extreme_words_w,[compare_word_w] = check_w_embedding([extreme_words_w,[compare_word_w]], model_g, True)\n",
    "metrics_w = compare_indirect_metrics(extreme_words_w, compare_word_w, model_g,g_gutenburg)\n",
    "print(\"indirect β values for word 'she':\", metrics_w)\n",
    "\n",
    "extreme_words_m,[compare_word_w] = check_w_embedding([extreme_words_m,[compare_word_m]], model_g, True)\n",
    "metrics_m = compare_indirect_metrics(extreme_words_m, compare_word_m, model_g,g_gutenburg)\n",
    "print(\"indirect β values for word 'he':\", metrics_m)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOv0RFFOX9NP"
   },
   "source": [
    "### 3.3 - WEAT Metric\n",
    "\n",
    "To measure WEAT, we used the formula defined in Caliskan et al., which is an additional direct bias measure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/WEAT.png\" style=\"width:300px;float:left;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_word_A_B(w,A,B,model):\n",
    "    mean_A_sum = 0\n",
    "    mean_B_sum = 0\n",
    "    w_v = w_vec(w,model)\n",
    "    \n",
    "    for a in A:\n",
    "        a_vec = w_vec(a,model)\n",
    "        mean_A_sum +=cos_sim(w_v,a_vec)\n",
    "    \n",
    "    for b in B:\n",
    "        b_vec = w_vec(b,model)\n",
    "        mean_B_sum +=cos_sim(w_v,b_vec)\n",
    "        \n",
    "    return mean_A_sum/len(A) - mean_B_sum/len(B)\n",
    "\n",
    "def s_X_Y_A_B(X,Y,A,B,model):\n",
    "    sum_X = 0\n",
    "    sum_Y = 0\n",
    "    \n",
    "    for x in X:\n",
    "        sum_X += s_word_A_B(x,A,B,model)\n",
    "        \n",
    "    for y in Y:\n",
    "        sum_Y += s_word_A_B(y,A,B,model)\n",
    "    \n",
    "    return sum_X - sum_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run experiments on the models <br>\n",
    "A and B are the attribute word groups (8 words each), and X,Y are the target words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEAT Exp 1: -0.006268933910178021\n",
      "WEAT Exp 2: -0.0604922525017173\n"
     ]
    }
   ],
   "source": [
    "#Experiment 1 - work/family\n",
    "A = ['tie', 'manager', 'work', 'paper', 'money', 'office', 'business', 'meeting']\n",
    "B = ['home', 'parents', 'children', 'family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "X = ['he', 'him']\n",
    "Y = ['she', 'her'] \n",
    "\n",
    "A,B,X,Y = check_w_embedding([A,B,X,Y], model_g, True)\n",
    "metric_exp_1_g = s_X_Y_A_B(X,Y,A,B,model_g)\n",
    "\n",
    "#A,B,X,Y = check_w_embedding([A,B,X,Y], model_w, True)\n",
    "#metric_exp_1_w = s_X_Y_A_B(X,Y,A,B,model_w)\n",
    "\n",
    "print (\"WEAT Exp 1:\", metric_exp_1_g)\n",
    "\n",
    "#Experiment 2 - professions\n",
    "A_2 = ['police', 'manager', 'business', 'lawyers', 'engineer', 'program', 'builder', 'fire']\n",
    "B_2 = ['teachers', 'clean', 'social', 'hair', 'nail', 'make', 'writer', 'library'] \n",
    "\n",
    "A_3,B_3,X,Y = check_w_embedding([A_2,B_2,X,Y], model_g, True)\n",
    "metric_exp_2_g = s_X_Y_A_B(X,Y,A_2,B_2,model_g)\n",
    "\n",
    "#A_3,B_3,X,Y = check_w_embedding([A_3,B_3,X,Y], model_w, True)\n",
    "#metric_exp_2_w = s_X_Y_A_B(X,Y,A_3,B_3,model_w)\n",
    "\n",
    "print (\"WEAT Exp 2:\", metric_exp_3_g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part1-Data-Collection-and-Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "240a2851180c468cab17cc15f43791a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e22f9386fc2478494dc1a2a9077d544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969dc2e4063943f18d5f138d173333de",
      "max": 258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8500834904d44de09d0be9b0ee202ba8",
      "value": 2
     }
    },
    "4f5b651b60e9480c845e33e7e56879cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b219d7af4654b309567abf230396944",
      "placeholder": "​",
      "style": "IPY_MODEL_970db59cdc1a41069843c019cd26edef",
      "value": "Dl Completed...:   0%"
     }
    },
    "5b219d7af4654b309567abf230396944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8500834904d44de09d0be9b0ee202ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "969dc2e4063943f18d5f138d173333de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970db59cdc1a41069843c019cd26edef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caf89f119045469380dba06fc031adb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df152c5f868e49f386d7ca98ae3f2ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f5b651b60e9480c845e33e7e56879cf",
       "IPY_MODEL_3e22f9386fc2478494dc1a2a9077d544",
       "IPY_MODEL_fa3ac15869974b3db2485239612e9a55"
      ],
      "layout": "IPY_MODEL_e8c31b3622284e2fa1a146714321b2f3"
     }
    },
    "e8c31b3622284e2fa1a146714321b2f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3ac15869974b3db2485239612e9a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_240a2851180c468cab17cc15f43791a9",
      "placeholder": "​",
      "style": "IPY_MODEL_caf89f119045469380dba06fc031adb6",
      "value": " 1/258 [00:00&lt;01:30,  2.85 file/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
