{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XP3YOprVwyX"
   },
   "source": [
    "# Exploring Gender Biases in Word2vec <br> \n",
    "\n",
    "This notebook defines genism's model and trains it with the Gutenburg and Wikipedia datasets. We also explore different embedding metrics to define a base comparision before we implement debiasing techniques. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "h4LSSjBdfJhI"
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "import torch\n",
    "from torch import nn, optim, sigmoid, softmax\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "import tempfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#gutenberg data import\n",
    "from gutenberg_data import get_urls, read_data_from_urls\n",
    "\n",
    "#model import\n",
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhIMaI4vV8VI"
   },
   "source": [
    "## 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RzDntNYcmVec"
   },
   "outputs": [],
   "source": [
    "def create_tokens(data):\n",
    "    \"\"\"\n",
    "    creates tokenized list with puncuation and digits removed and lowercase words \n",
    "\n",
    "    :param data: list of strings\n",
    "    :return: a list of tokens \n",
    "    \"\"\" \n",
    "    tokens = []\n",
    "    for sentance in data:\n",
    "      #split into tokens, convert to lowercase \n",
    "      sentance = sentance.translate(str.maketrans('', '', string.punctuation)) #remove punctuations\n",
    "      sentance = sentance.translate(str.maketrans('', '', string.digits)) #remove digits\n",
    "      tokenizer = get_tokenizer(\"basic_english\", language=\"en\") #remove unessasary characters, splits into spaces\n",
    "      tokens.append(tokenizer(sentance))\n",
    "  \n",
    "    return tokens\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gutenburg Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gutenburg\n",
    "train_urls = get_urls('test')\n",
    "train_data_g = read_data_from_urls(train_urls)\n",
    "train_data_g=str(train_data_g[0]).split('.')\n",
    "\n",
    "sentences_gutenburg = create_tokens(train_data_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wikipedia Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wikipedia\n",
    "f = open('wikipedia-en-1000.json')\n",
    "train_data_w = json.load(f)\n",
    "train_data_w =str(train_data_w[0]).split('.')\n",
    "\n",
    "sentences_wikipedia = create_tokens(train_data_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Define Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vADvrY8rDeuq"
   },
   "source": [
    "**Define word 2 vec model** <br>\n",
    "\n",
    "Using: Skip-gram training algorithm. \n",
    "\n",
    "Hyperparameters:\n",
    "- min_freq: choosing the top N most frequent words - for easier training \n",
    "- size: embedding size. We use 300 as per ____ et. al\n",
    "- window: the window used for looking at context and center words when traing the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1\n",
    "size = 300\n",
    "window = 10\n",
    "\n",
    "#gutenburg model \n",
    "model_g = Word2Vec(min_count=min_freq, vector_size=size, window=window, sg=1) #sg=1 is the skip-gram training algorithm\n",
    "model_g.init_weights()\n",
    "model_g.build_vocab(sentences_gutenburg) \n",
    "\n",
    "\n",
    "#wikipedia model\n",
    "model_w = Word2Vec(min_count=min_freq, vector_size=size, window=window, sg=1) #sg=1 is the skip-gram training algorithm\n",
    "model_w.init_weights()\n",
    "model_w.build_vocab(sentences_wikipedia) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful helper functions for model\n",
    "\n",
    "def check_w_embedding(word_lists, model, printRemoved):\n",
    "    '''\n",
    "    returns the cosine similarity between 2 word embeddings \n",
    "    '''\n",
    "    new_w_lists = []\n",
    "    \n",
    "    for word_list in word_lists:\n",
    "        new_w_l = []\n",
    "        for w in word_list: \n",
    "            if w in model.wv.key_to_index:\n",
    "                new_w_l.append(w)\n",
    "            else:\n",
    "                if printRemoved:\n",
    "                    print (\"Word\", w, \" is not in the model\")\n",
    "                    \n",
    "        new_w_lists.append(new_w_l)\n",
    "    \n",
    "    return new_w_lists\n",
    "    \n",
    "\n",
    "def w_vec(word):\n",
    "    '''\n",
    "    returns the word embedding of the input word\n",
    "    '''\n",
    "    return model.wv[word]\n",
    "   \n",
    "\n",
    "def cos_sim(a,b):\n",
    "    '''\n",
    "    returns the cosine similarity between 2 word embeddings \n",
    "    '''\n",
    "    return np.dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, save the embeddings to use in debiasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gutenburg_embeddings.txt', 'w') as f:\n",
    "    for idx, key in enumerate(list(model_g.wv.index_to_key)):\n",
    "        embedding = ' '.join(str(v) for v in model_g.wv.get_vector(key))\n",
    "        f.write(key + \" \" + embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikipedia_embeddings.txt', 'w') as f:\n",
    "    for idx, key in enumerate(list(model_w.wv.index_to_key)):\n",
    "        embedding = ' '.join(str(v) for v in model_w.wv.get_vector(key))\n",
    "        f.write(key + \" \" + embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<gensim.models.keyedvectors.KeyedVectors object at 0x7fde43bed730>\n",
      "<gensim.models.keyedvectors.KeyedVectors object at 0x7fde49d0c610>\n",
      "[-1.65785546e-03 -4.27768216e-04  1.09354581e-03 -2.13801139e-03\n",
      " -3.23386351e-03 -3.08674504e-03  3.00689857e-03  1.79056404e-03\n",
      " -1.59607572e-03 -2.77654734e-03  4.31316701e-04  9.59354220e-04\n",
      " -4.15094692e-04  4.23623715e-04 -1.44043448e-03  1.59712159e-03\n",
      "  4.91728017e-04  2.95927445e-03 -3.32550448e-03 -1.75652350e-03\n",
      " -3.03428085e-03 -1.15973155e-04 -2.61910190e-03  1.67707994e-03\n",
      " -2.13228539e-03 -1.98427914e-03  1.69030344e-03 -2.71992292e-03\n",
      "  4.85067372e-04 -2.41318066e-03  3.28747346e-03  2.87791970e-03\n",
      "  5.89650474e-04  1.92950096e-03  1.53207139e-03 -1.99726108e-03\n",
      "  3.25231557e-03 -3.22740246e-03  2.68308562e-03  9.18792910e-04\n",
      " -1.01837399e-03 -1.18728797e-03  3.02398438e-03 -1.81363663e-03\n",
      "  2.72895745e-03 -2.00296240e-03  2.79712514e-03 -1.85164608e-04\n",
      "  2.64753262e-03 -1.05165725e-03  1.99307129e-03  2.93478160e-03\n",
      "  8.47945979e-04  4.39249678e-04  1.67973037e-03  2.66750739e-03\n",
      "  2.85600428e-03  2.83092423e-03  2.35084211e-03  2.66754953e-03\n",
      "  2.86657969e-03 -1.10308329e-05 -3.34577548e-04  5.55263367e-04\n",
      "  1.09116240e-06  2.28392280e-04 -2.86697946e-03 -3.19824368e-03\n",
      " -7.71559076e-04  2.97606620e-03 -1.21586246e-03 -2.32606498e-03\n",
      "  1.62646058e-03  3.56372184e-04  6.17006619e-04  1.21765211e-03\n",
      "  1.17355748e-03  1.90870685e-03  4.11433371e-04  2.81487301e-04\n",
      "  3.01508349e-03  9.27405374e-04 -1.56761880e-03  2.18072883e-03\n",
      "  1.73777028e-03  9.56855598e-04 -1.04594463e-03  1.11227832e-03\n",
      "  2.12143268e-03  2.36034626e-03  3.13721510e-04 -2.84392270e-03\n",
      "  8.59204956e-05  1.23473015e-04  1.31432689e-03 -3.15632019e-03\n",
      "  3.23595689e-03 -2.32409243e-03  1.92047993e-03 -3.14329076e-03\n",
      "  3.21617606e-03  2.44160974e-03  4.20552096e-04 -1.13507907e-03\n",
      " -1.50220396e-04  1.40874385e-04 -2.13640206e-03  1.91505277e-03\n",
      "  7.90467253e-04  1.25931180e-03 -2.41833925e-03  2.84209638e-03\n",
      "  1.69417865e-04 -6.79755176e-05 -3.02386913e-03  1.34958501e-03\n",
      "  2.25447817e-03  2.45169713e-03 -2.13917485e-03 -2.61868723e-03\n",
      " -1.84123835e-03 -2.00966198e-04 -2.77932733e-03 -2.74670520e-03\n",
      " -6.39189908e-04  3.79761856e-04 -3.16884904e-03 -1.24431134e-03\n",
      "  2.14926404e-04  2.26998795e-03  5.78330364e-04 -2.10794606e-04\n",
      " -2.49379873e-03 -2.24736542e-03 -2.31476632e-04  2.48919404e-03\n",
      "  1.81428983e-03 -4.94230597e-04  3.90769652e-04 -3.20192566e-03\n",
      " -4.61498887e-04 -1.54207472e-03  1.93643651e-03 -7.79337890e-04\n",
      " -1.58802187e-03 -3.15837143e-03 -4.00105317e-04 -2.39925692e-03\n",
      " -5.61739609e-04 -1.35660812e-03 -7.91378843e-04 -1.08277879e-03\n",
      " -2.71882466e-03 -4.16137365e-04  5.63647773e-04 -1.34921470e-03\n",
      " -2.54715118e-03 -1.19554519e-03 -3.01571121e-03 -2.52808735e-04\n",
      "  1.96100166e-03 -9.87115665e-04  1.05391897e-03  1.66523934e-03\n",
      "  2.82280915e-03  1.87380472e-03  3.16951517e-03 -3.21556092e-03\n",
      " -2.65422510e-03 -2.25271867e-03 -2.48923618e-03 -2.65453965e-03\n",
      " -2.59605655e-03 -9.80875455e-04  4.65386722e-04 -9.58263059e-04\n",
      " -2.93875067e-03  1.66195398e-03  3.00296932e-04  1.53013389e-03\n",
      "  2.39844550e-03  2.54943129e-03 -2.68216128e-04  1.21998624e-03\n",
      " -1.70785899e-03  6.36893907e-04  1.51275634e-03  3.29555431e-03\n",
      " -1.06249645e-03  9.46444692e-04 -1.91211700e-03 -7.36855669e-04\n",
      "  2.70836521e-03 -1.30155240e-03 -3.96193675e-04 -3.09499190e-03\n",
      " -3.15892533e-03  2.96092196e-03 -1.90097408e-03  1.68426358e-03\n",
      " -2.32120277e-03 -8.19504261e-04 -2.67431256e-03  2.50017573e-03\n",
      "  2.04247166e-03  1.75282324e-03  2.79261917e-03 -2.32177568e-04\n",
      " -3.10424319e-03  3.03855492e-03 -1.64284545e-03  2.61599617e-03\n",
      "  1.84461987e-03 -3.59692582e-04 -2.55473843e-03 -4.86601202e-04\n",
      "  2.08451203e-03 -2.32202769e-03  4.80698742e-04 -2.65061925e-03\n",
      "  2.90711573e-03 -9.51929891e-04  3.14576714e-03 -1.90269155e-03\n",
      " -3.23924143e-03 -2.87596788e-03 -1.35827856e-03  1.56986481e-03\n",
      " -8.06466705e-05  3.07450374e-03  1.03640475e-03  1.24925538e-03\n",
      "  9.98783158e-04  2.71621626e-03 -7.98904919e-04  2.46911286e-03\n",
      " -3.17890476e-03  9.73695132e-04 -2.27223238e-04  1.50752065e-04\n",
      "  2.28100293e-03 -9.47324443e-04 -7.85593176e-04 -3.34922479e-05\n",
      " -1.65897203e-04 -1.19165424e-03  2.08149431e-03 -2.18622293e-03\n",
      "  2.63066613e-03 -3.11533622e-05  8.69613490e-04  1.07438327e-03\n",
      " -9.38844678e-05  5.68767369e-04 -1.04688480e-03  1.58548518e-03\n",
      "  8.10035053e-05 -1.09353219e-03 -2.90485867e-03 -3.33269360e-03\n",
      "  1.04258856e-04 -1.91560353e-03 -3.69886548e-04 -1.40203163e-03\n",
      " -2.87960842e-03  3.54031712e-04  1.97036355e-03 -7.36989954e-04\n",
      " -2.39027268e-03  1.05114537e-03 -1.28228668e-04 -1.84038084e-03\n",
      " -3.68543464e-04 -2.13218533e-04 -1.06103020e-03 -3.31835914e-03\n",
      "  2.54619750e-03  1.24200259e-03 -8.43071146e-04  2.43572472e-03\n",
      "  1.51530112e-04  2.39105057e-03 -5.15854335e-04  2.49788910e-03\n",
      " -1.42105418e-05 -2.02578702e-03 -1.57195015e-03  3.20947496e-03\n",
      "  1.93687287e-04  3.42466839e-04  2.81676208e-03 -2.09613494e-03\n",
      " -5.87952905e-04 -2.72630691e-03 -2.22491822e-03 -2.86016217e-03\n",
      "  1.31020311e-03  9.13115335e-04  1.87180436e-03  8.57252278e-04]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model_g.wv\n",
    "word_vectors.save('vectors.kv')\n",
    "print(word_vectors)\n",
    "reloaded_word_vectors = KeyedVectors.load('vectors.kv')\n",
    "print(reloaded_word_vectors)\n",
    "print(reloaded_word_vectors.get_vector(\"he\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-1', delete=False) as tmp:\n",
    "    temporary_filepath = 'hi.txt'\n",
    "    model_g.save(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9jws4VUXiuh"
   },
   "source": [
    "## 3 - Measuring Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ylrwq0MXxYN"
   },
   "source": [
    "### 3.1 - Direct Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMIUMyqsX57J"
   },
   "source": [
    "### 3.2 - Indirect Bias\n",
    "\n",
    "\n",
    "For indirect bias, we can define the gender component of words, β(w, v), by defining wg , the contribution from gender, and w⊥ = w −wg, where the word vectors w are unit normal. The equation for β(w, v) from Bolukbasi et al.  is shown below. \n",
    "\t\t\t\t(w, v)= (wv - wv||w||2||v||2)/(wv)\n",
    "Larger β(w, v) suggest similarity of embeddings that have no relation (softball and receptionist) which can be largely explained by gender biases in the embedding. Furthermore, to visualize these similarities, we can use k-means to split the embeddings into clusters and analyze the indirect bias that way, as was done in Gohen et al. \n",
    "\n",
    "wg = (w · g)g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_indirect_metric(g, w, v):\n",
    "    wg= np.dot(np.dot(w,g),g)\n",
    "    vg = np.dot(np.dot(v,g),g)\n",
    "    w_norm_vec = w-wg\n",
    "    v_norm_vec =v-vg\n",
    "    w_norm = norm(w_norm_vec)\n",
    "    v_norm = norm(v_norm_vec)\n",
    "    \n",
    "    return (np.dot(w,v) - np.dot(w_norm_vec,v_norm_vec)/(w_norm*v_norm))/np.dot(w,v)\n",
    "\n",
    "\n",
    "#need to define w, v words which we want to calulate this metric on (in a loop)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOv0RFFOX9NP"
   },
   "source": [
    "### 3.3 - WEAT Metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- so far only works for google's word2vec model \n",
    "- based on the equations: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_word_A_B(w,A,B):\n",
    "    mean_A_sum = 0\n",
    "    mean_B_sum = 0\n",
    "    w_v = w_vec(w)\n",
    "    \n",
    "    for a in A:\n",
    "        a_vec = w_vec(a)\n",
    "        mean_A_sum +=cos_sim(w_v,a_vec)\n",
    "    \n",
    "    for b in B:\n",
    "        b_vec = w_vec(b)\n",
    "        mean_B_sum +=cos_sim(w_v,b_vec)\n",
    "        \n",
    "    return mean_A_sum/len(A) - mean_B_sum/len(B)\n",
    "\n",
    "def s_X_Y_A_B(X,Y,A,B):\n",
    "    sum_X = 0\n",
    "    sum_Y = 0\n",
    "    \n",
    "    for x in X:\n",
    "        sum_X += s_word_A_B(x,A,B)\n",
    "        \n",
    "    for y in Y:\n",
    "        sum_Y += s_word_A_B(y,A,B)\n",
    "    \n",
    "    return sum_X - sum_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run 3 experiments on the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006268933910178021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Experiment 1\n",
    "\n",
    "#A and B are the attribute word groups \n",
    "A = ['tie', 'manager', 'work', 'paper', 'money', 'office', 'business', 'meeting']\n",
    "B = ['home', 'parents', 'children', 'family', 'sister', 'marriage', 'charm', 'relatives']\n",
    "\n",
    "#target words \n",
    "X = ['he', 'him'] #male \n",
    "Y = ['she', 'her'] #female\n",
    "\n",
    "A,B,X,Y = check_w_embedding([A,B,X,Y], model, True)\n",
    "\n",
    "metric_exp_1 = s_X_Y_A_B(X,Y,A,B)\n",
    "\n",
    "print (metric_exp_1)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part1-Data-Collection-and-Word2Vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "240a2851180c468cab17cc15f43791a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e22f9386fc2478494dc1a2a9077d544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_969dc2e4063943f18d5f138d173333de",
      "max": 258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8500834904d44de09d0be9b0ee202ba8",
      "value": 2
     }
    },
    "4f5b651b60e9480c845e33e7e56879cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b219d7af4654b309567abf230396944",
      "placeholder": "​",
      "style": "IPY_MODEL_970db59cdc1a41069843c019cd26edef",
      "value": "Dl Completed...:   0%"
     }
    },
    "5b219d7af4654b309567abf230396944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8500834904d44de09d0be9b0ee202ba8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "969dc2e4063943f18d5f138d173333de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "970db59cdc1a41069843c019cd26edef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caf89f119045469380dba06fc031adb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df152c5f868e49f386d7ca98ae3f2ade": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4f5b651b60e9480c845e33e7e56879cf",
       "IPY_MODEL_3e22f9386fc2478494dc1a2a9077d544",
       "IPY_MODEL_fa3ac15869974b3db2485239612e9a55"
      ],
      "layout": "IPY_MODEL_e8c31b3622284e2fa1a146714321b2f3"
     }
    },
    "e8c31b3622284e2fa1a146714321b2f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa3ac15869974b3db2485239612e9a55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_240a2851180c468cab17cc15f43791a9",
      "placeholder": "​",
      "style": "IPY_MODEL_caf89f119045469380dba06fc031adb6",
      "value": " 1/258 [00:00&lt;01:30,  2.85 file/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
